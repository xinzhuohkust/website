{"title":"Online Captcha Solving When Using R for Web Scraping","markdown":{"yaml":{"title":"Online Captcha Solving When Using R for Web Scraping","date":"Oct 28, 2023","categories":["R","Python","OCR","Wec Scraping"],"description":"use OCR","code-fold":"show","feed":true,"cap-location":"bottom","execute":{"warning":false,"message":false},"citation":{"author":"Huang Xinzhuo"}},"containsRefs":false,"markdown":"\n\n```{=html}\n<style>\nbody {text-align: justify}\n</style>\n```\n![](captcha.jpg){fig-align=\"center\" width=\"300\"}\n\nHow to write a robust web scraper using R that can automatically bypass captcha checks? Our basic solution is as follows:\n\nFirstly, maintain a logged-in state with `httr`. Next, download the captcha locally. Following this, import the Python module [`ddddocr`](https://github.com/sml2h3/ddddocr) for OCR recognition to identify the characters in the captcha. After the captcha has been successfully identified, we submit it to bypass the verification.\n\nThis allows us to continue with our web scraping activities unhindered. In web scraping, effective exception handling is rather important, and the functional programming tools provided by `purrr` can be incredibly helpful.\n\n```{r}\n#| code-fold: true\n#| code-summary: Pakcage Management\nrequire(pacman)\np_load(reticulate, httr, tidyverse, rvest, reactable, tippy, htmltools)\n```\n\n```{r}\n#| eval: false\nhandle <- handle(\"sample_website\")\n\nGET(\n    \"sample_website\", \n    handle = handle, \n    write_disk(\"blog/captcha/captcha_new.jpg\", overwrite = TRUE)\n)\n```\n\n![](captcha_new.png){fig-align=\"center\" width=\"200\"}\n\nOCR recognition:\n\n```{r}\n#| eval: false\nreticulate::use_python(\"C:\\\\Users\\\\xhuangcb\\\\anaconda3\\\\envs\\\\pytorch_gpu\\\\python.exe\")\n\nddddocr <- reticulate::import(\"ddddocr\")\n\nocr <- ddddocr$DdddOcr(beta = TRUE)\n\nbuiltins <- import_builtins()\n\nf <- builtins$open(\"blog/captcha/captcha_new.jpg\", \"rb\")\n\nimage <- f$read()\n\nyzm <- ocr$classification(image)\n```\n\n```{r}\n#| echo: false\nyzm <- \"nf353\"\nyzm\n```\n\nAfter submission, the status code is 200, indicating success.\n\n```{r}\n#| eval: false\nresponse <- POST(\n    \"sample_website\",\n    body = list(yzm = yzm),\n    handle = handle\n)\n\nresponse$status_code\n```\n\n```{r}\n#| echo: false\n200\n```\n\nLet's integrate the OCR module into our web scraping process. With the powerful exception handling provided by `purrr`, we can create a more robust web scraper, which supports automatic retry and bypassing captchas.\n\n```{r}\n#| eval: false\nextract_links <- possibly(\n    insistently(\n        \\(page_num = 1, source = 2, sleep = sample(seq(2, 5, 0.05), 1), location = NULL) {\n            page <- POST(\n                url = \"sample_website\",\n                encode = \"form\",\n                body = list(\n                    `ajlb` = \"2\",\n                    `st` = \"1\",\n                    `jbfyId` = \"\",\n                    `sxnflx` = \"0\",\n                    `zscq` = \"\",\n                    `cwslbmc` = \"\",\n                    `prompt` = \"\",\n                    `dsrName` = \"\",\n                    `ajmc` = \"\",\n                    `ay` = \"\",\n                    `ah` = \"\",\n                    `startCprq` = \"2013-01-01\",\n                    `endCprq` = \"2023-10-23\",\n                    `page` = page_num\n                ),\n                handle = handle\n            )\n\n            sign <- page %>%\n                read_html() %>%\n                html_text() %>%\n                str_remove_all(\"\\\\\\r|\\\\\\n|\\\\\\t|\\\\s+|\\\\p{P}\")\n\n            if (sign == \"varcontextPath=提交\") {\n                GET(\n                    \"sample_website\",\n                    handle = handle,\n                    write_disk(\"blog/captcha/captcha_new.jpg\", overwrite = TRUE)\n                )\n\n                yzm <- ocr$classification(image)\n\n                response <- POST(\n                    \"sample_website\",\n                    body = list(yzm = yzm),\n                    handle = handle\n                )\n\n                if(response$status_code != 200) {stop(\"OCR failed!\")}\n                \n            } else {\n                links <- page %>%\n                    read_html() %>% \n                    html_elements(xpath = \"//li[@class='refushCpws']\") %>%\n                    html_nodes(\"a\")\n\n                id <- links %>%\n                    html_attr(\"href\")\n\n                title <- links %>%\n                    html_text(trim = TRUE)\n\n                courts <- page %>%\n                    read_html() %>%\n                    html_elements(xpath = \"//span[@class='sp_right']\")\n\n                court <- courts %>%\n                    html_elements(xpath = \"//span[@class='sp_name']\") %>%\n                    html_text(trim = TRUE)\n\n                date <- courts %>%\n                    html_elements(xpath = \"//span[@class='sp_time']\") %>%\n                    html_text(trim = TRUE)\n\n                result <- tibble(\n                    id = id,\n                    title = title,\n                    court = court,\n                    date = date\n                )\n            }\n\n            Sys.sleep(sleep)\n\n            if (is.null(location)) {\n                return(result)\n            } else {\n                write_rds(result, file = str_c(location, \"/\", page_num, \".Rds\"))\n            }\n        },\n        rate = rate_backoff(\n            pause_base = 2,\n            pause_cap = 60,\n            pause_min = 1,\n            max_times = 10,\n            jitter = TRUE\n        )\n    )\n)\n\nresult <- map(1:10, extract_links, .progress = TRUE) \n```\n\n<br> The results of running this web scraper are as follows:\n\n```{r}\n#| echo: false\nrender_reactable_cell_with_tippy <- function(text, tooltip) {\n    div(\n        style = \"max-width: 800px; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;\",\n        tippy(text = text, tooltip = tooltip)\n    )\n}\n\ndata2 <- read_rds(\"sample.Rds\") %>%\n    mutate(\n    across(everything(), ~ str_replace_all(., \".{2}市(.{2,4}区)?\", \"***\")),\n    Date = ymd(date),\n    Title = title,\n    Court = court\n) %>%\n    arrange(desc(Date)) %>% \n    select(Date, Title, Court)\n\ntable2 <- reactable(data2,\n    searchable = TRUE,\n    theme = reactableTheme(\n        headerStyle = list(\n            \"&:hover[aria-sort]\" = list(background = \"hsl(0, 0%, 96%)\"),\n            \"&[aria-sort='ascending'], &[aria-sort='descending']\" = list(background = \"hsl(0, 0%, 96%)\"),\n            borderColor = \"#555\"\n        )\n    ),\n    columns = list(\n        `Title` = colDef(\n            html = TRUE,\n            cell = function(value, index, name) {\n                render_reactable_cell_with_tippy(text = value, tooltip = value)\n            }\n        )\n    )\n)\n\ntable2 \n```\n","srcMarkdownNoYaml":"\n\n```{=html}\n<style>\nbody {text-align: justify}\n</style>\n```\n![](captcha.jpg){fig-align=\"center\" width=\"300\"}\n\nHow to write a robust web scraper using R that can automatically bypass captcha checks? Our basic solution is as follows:\n\nFirstly, maintain a logged-in state with `httr`. Next, download the captcha locally. Following this, import the Python module [`ddddocr`](https://github.com/sml2h3/ddddocr) for OCR recognition to identify the characters in the captcha. After the captcha has been successfully identified, we submit it to bypass the verification.\n\nThis allows us to continue with our web scraping activities unhindered. In web scraping, effective exception handling is rather important, and the functional programming tools provided by `purrr` can be incredibly helpful.\n\n```{r}\n#| code-fold: true\n#| code-summary: Pakcage Management\nrequire(pacman)\np_load(reticulate, httr, tidyverse, rvest, reactable, tippy, htmltools)\n```\n\n```{r}\n#| eval: false\nhandle <- handle(\"sample_website\")\n\nGET(\n    \"sample_website\", \n    handle = handle, \n    write_disk(\"blog/captcha/captcha_new.jpg\", overwrite = TRUE)\n)\n```\n\n![](captcha_new.png){fig-align=\"center\" width=\"200\"}\n\nOCR recognition:\n\n```{r}\n#| eval: false\nreticulate::use_python(\"C:\\\\Users\\\\xhuangcb\\\\anaconda3\\\\envs\\\\pytorch_gpu\\\\python.exe\")\n\nddddocr <- reticulate::import(\"ddddocr\")\n\nocr <- ddddocr$DdddOcr(beta = TRUE)\n\nbuiltins <- import_builtins()\n\nf <- builtins$open(\"blog/captcha/captcha_new.jpg\", \"rb\")\n\nimage <- f$read()\n\nyzm <- ocr$classification(image)\n```\n\n```{r}\n#| echo: false\nyzm <- \"nf353\"\nyzm\n```\n\nAfter submission, the status code is 200, indicating success.\n\n```{r}\n#| eval: false\nresponse <- POST(\n    \"sample_website\",\n    body = list(yzm = yzm),\n    handle = handle\n)\n\nresponse$status_code\n```\n\n```{r}\n#| echo: false\n200\n```\n\nLet's integrate the OCR module into our web scraping process. With the powerful exception handling provided by `purrr`, we can create a more robust web scraper, which supports automatic retry and bypassing captchas.\n\n```{r}\n#| eval: false\nextract_links <- possibly(\n    insistently(\n        \\(page_num = 1, source = 2, sleep = sample(seq(2, 5, 0.05), 1), location = NULL) {\n            page <- POST(\n                url = \"sample_website\",\n                encode = \"form\",\n                body = list(\n                    `ajlb` = \"2\",\n                    `st` = \"1\",\n                    `jbfyId` = \"\",\n                    `sxnflx` = \"0\",\n                    `zscq` = \"\",\n                    `cwslbmc` = \"\",\n                    `prompt` = \"\",\n                    `dsrName` = \"\",\n                    `ajmc` = \"\",\n                    `ay` = \"\",\n                    `ah` = \"\",\n                    `startCprq` = \"2013-01-01\",\n                    `endCprq` = \"2023-10-23\",\n                    `page` = page_num\n                ),\n                handle = handle\n            )\n\n            sign <- page %>%\n                read_html() %>%\n                html_text() %>%\n                str_remove_all(\"\\\\\\r|\\\\\\n|\\\\\\t|\\\\s+|\\\\p{P}\")\n\n            if (sign == \"varcontextPath=提交\") {\n                GET(\n                    \"sample_website\",\n                    handle = handle,\n                    write_disk(\"blog/captcha/captcha_new.jpg\", overwrite = TRUE)\n                )\n\n                yzm <- ocr$classification(image)\n\n                response <- POST(\n                    \"sample_website\",\n                    body = list(yzm = yzm),\n                    handle = handle\n                )\n\n                if(response$status_code != 200) {stop(\"OCR failed!\")}\n                \n            } else {\n                links <- page %>%\n                    read_html() %>% \n                    html_elements(xpath = \"//li[@class='refushCpws']\") %>%\n                    html_nodes(\"a\")\n\n                id <- links %>%\n                    html_attr(\"href\")\n\n                title <- links %>%\n                    html_text(trim = TRUE)\n\n                courts <- page %>%\n                    read_html() %>%\n                    html_elements(xpath = \"//span[@class='sp_right']\")\n\n                court <- courts %>%\n                    html_elements(xpath = \"//span[@class='sp_name']\") %>%\n                    html_text(trim = TRUE)\n\n                date <- courts %>%\n                    html_elements(xpath = \"//span[@class='sp_time']\") %>%\n                    html_text(trim = TRUE)\n\n                result <- tibble(\n                    id = id,\n                    title = title,\n                    court = court,\n                    date = date\n                )\n            }\n\n            Sys.sleep(sleep)\n\n            if (is.null(location)) {\n                return(result)\n            } else {\n                write_rds(result, file = str_c(location, \"/\", page_num, \".Rds\"))\n            }\n        },\n        rate = rate_backoff(\n            pause_base = 2,\n            pause_cap = 60,\n            pause_min = 1,\n            max_times = 10,\n            jitter = TRUE\n        )\n    )\n)\n\nresult <- map(1:10, extract_links, .progress = TRUE) \n```\n\n<br> The results of running this web scraper are as follows:\n\n```{r}\n#| echo: false\nrender_reactable_cell_with_tippy <- function(text, tooltip) {\n    div(\n        style = \"max-width: 800px; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;\",\n        tippy(text = text, tooltip = tooltip)\n    )\n}\n\ndata2 <- read_rds(\"sample.Rds\") %>%\n    mutate(\n    across(everything(), ~ str_replace_all(., \".{2}市(.{2,4}区)?\", \"***\")),\n    Date = ymd(date),\n    Title = title,\n    Court = court\n) %>%\n    arrange(desc(Date)) %>% \n    select(Date, Title, Court)\n\ntable2 <- reactable(data2,\n    searchable = TRUE,\n    theme = reactableTheme(\n        headerStyle = list(\n            \"&:hover[aria-sort]\" = list(background = \"hsl(0, 0%, 96%)\"),\n            \"&[aria-sort='ascending'], &[aria-sort='descending']\" = list(background = \"hsl(0, 0%, 96%)\"),\n            borderColor = \"#555\"\n        )\n    ),\n    columns = list(\n        `Title` = colDef(\n            html = TRUE,\n            cell = function(value, index, name) {\n                render_reactable_cell_with_tippy(text = value, tooltip = value)\n            }\n        )\n    )\n)\n\ntable2 \n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"kable","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"show","code-overflow":"scroll","code-link":true,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../../scss/styles.css"],"highlight-style":"gruvbox","toc":true,"toc-depth":3,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","preview":{"port":5555,"browser":true,"watch-inputs":true,"navigate":true},"bibliography":["../../../bib/references.bib"],"csl":"../../../bib/chicago-author-date.csl","knitr":{"opts_chunk":{"warning":false,"message":false,"error":false}},"code-annotations":"hover","editor":"visual","theme":{"light":["flatly","../../../scss/light.scss"],"dark":["darkly","../../../scss/dark.scss"]},"author":[{"name":"Xinzhuo Huang","orcid":"0009-0007-6448-5114","email":"xhuangcb@connect.ust.hk","affiliations":[{"name":"HKUST SOSC"}]}],"smooth-scroll":true,"code-block-bg":"#f5f5f5","code-block-border-left":"#E0E0E0","date-modified":"last-modified","toc-location":"right","link-citations":"yes","comments":{"giscus":{"repo":"xinzhuohkust/comments","theme":"light"},"hypothesis":{"theme":"clean"}},"title":"Online Captcha Solving When Using R for Web Scraping","date":"Oct 28, 2023","categories":["R","Python","OCR","Wec Scraping"],"description":"use OCR","feed":true,"cap-location":"bottom","citation":{"author":"Huang Xinzhuo"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}