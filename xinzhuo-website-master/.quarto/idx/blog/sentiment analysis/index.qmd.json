{"title":"Sentence Level Sentiment Analysis","markdown":{"yaml":{"title":"Sentence Level Sentiment Analysis","date":"Feb 20 2023","categories":["R","Python","Sentiment Analysis","Reticulate"],"description":"by calling Python in R","code-fold":"show","feed":true},"headingText":"Pacakage Management","containsRefs":false,"markdown":"\n\n```{=html}\n<style>\nbody {text-align: justify}\n</style>\n```\n![](images/sentiment.png){fig-align=\"center\" width=\"500\"}\n\nText analysis enables the identification and extraction of sentiment information from text. By leveraging tools such as `asent`, `sentimentr`, and basic sentiment lexicons, it is possible to construct a sentiment classifier that can estimate whether the underlying sentiment of a given text is positive, negative, or neutral.\n\n\nUsing `pacman` to manage package dependencies.\n\n```{r message=FALSE, warning=FALSE}\nrequire(pacman)\np_load(dplyr, magrittr, furrr, purrr, DT, readr, stringr, furrr, purrr, sentimentr, tidyfst, tidyr, textclean, tidytext, tibble, kableExtra)\n```\n\n# Load Data\n\nOur demonstration data are sourced from a news dataset collected from Factiva, consisting of 500 observations. The \"link\" refers to the links of these news articles. These news articles have been translated into English and undergone thorough text cleaning. Please find the data [here.](https://drive.google.com/file/d/1JKj8rDatjionAYN1EhzFnSNBRNQkay0C/view){.external target=\"_blank\"}\n\n```{r}\ndata <- read_rds(\"E:/OneDrive - HKUST Connect/SOSC/paper_with_jean/group_meeting/fifth/data_for_analysis_share.Rds\")\nglimpse(data)\n```\n\n# Using asent\n\nTo use `asent`, a Python package in R, you need `reticulate` package to integrate Python code in your R script. You can change your python interpreter here:\n\n![](images/python_in_R.png){width=\"550\"}\n\n## install python packages:\n\nCall python in R.\n\n```{r message=FALSE}\nreticulate::use_python(\"C:\\\\Users\\\\xhuangcb\\\\anaconda3\\\\envs\\\\pytorch_gpu\\\\python.exe\") # call python in R\n```\n\nThen:\n\n```{r}\n#| echo: false\ntribble(\n    ~\"Tpying\", ~\"To install\",\n    \"!pip install spacy\", \"spacy\",\n    \"!pip install asent\", \"asent\",\n    \"!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl\", \"pre-trained model\"\n) %>% \n   kbl() %>%\n   kable_styling()\n```\n\n![](images/callpythoninr.png){width=\"550\"}\n\n## from OOP to FP\n\nPython is an object-oriented programming (OOP) language, and it is possible to convert Python classes into functions in R, which mainly support functional programming (FP).\n\n```{r message=FALSE}\nspacy <- reticulate::import(\"spacy\") # load spacy\n\nasent <- reticulate::import(\"asent\") # load asent\n\nnlp <- spacy$load(\"en_core_web_lg\") # load pre-trained model\n\nnlp$add_pipe(\"asent_en_v1\") # add asent pipe\n\nnlp_safe <- possibly(.f = nlp, otherwise = \"error!\") # error handling\n\nget_polarity <- nlp_safe(\"sentiment\")$get_extension(\"polarity\")[[3]] # load python function\n\nget_sentiment_asent <- \\(x) {\n    result <- nlp_safe(x) %>%\n        get_polarity() %>%\n        print() %>%\n        capture.output() %>%\n        str_extract_all(\"-?0\\\\.\\\\d+\") %>%\n        unlist() %>%\n        as.numeric()\n\n    names(result) <- c(\"neg\", \"neu\", \"pos\", \"compound\")\n\n    return(result)\n}\n```\n\nTry our function:\n\n```{r}\nget_sentiment_asent(data$cleaned_text[1])\n```\n\nIt is an analytical process of asent:\n\n![](images/result-01.png){width=\"680\"}\n\n# Using sentimentr\n\nOur function using `sentimentr`.\n\n```{r}\nget_sentences_safe <- possibly(.f = get_sentences, otherwise = \"error!\") # sentences cutter\n\nsentiment_by_safe <- possibly(.f = sentiment_by, otherwise = \"error!\") # sentiment classifier\n\nget_sentiemnt_sentimentr <- \\(x) {\n    x %>%\n        get_sentences_safe() %>%\n        sentiment_by_safe() %>%\n        unlist()\n}\n```\n\nTry it:\n\n```{r}\nget_sentiemnt_sentimentr(data$cleaned_text[1])\n```\n\n# Word-level\n\n```{r}\ncal_sentiment <- \\(x) {\n    x %>%\n        filter(value == 0) %>%\n        pull(value) %>%\n        length() -> neu\n\n    x %>%\n        filter(value > 0) %>%\n        pull(value) %>%\n        sum() -> pos\n\n    x %>%\n        filter(value < 0) %>%\n        pull(value) %>%\n        sum() -> neg\n    result <- c(neu, pos, neg)\n\n    names(result) <- c(\"neu\", \"pos\", \"neg\")\n\n    return(result)\n}\n\nget_sentiment_word <- \\(x) {\n    result <- x %>%\n        tibble(text = ., id = 1) %>%\n        unnest_tokens(word, text) %>%\n        filter(!word %in% stopwords::stopwords(source = \"stopwords-iso\")) %>%\n        left_join(get_sentiments(\"afinn\")) %>% # you can try different dict\n        replace_na(list(value = 0)) %>%\n        nest(data = !id) %>%\n        mutate(sentiment = map(data, cal_sentiment)) %>%\n        pull(sentiment) %>%\n        unlist()\n\n    return(result)\n}\n```\n\nTry it:\n\n```{r message=FALSE}\nget_sentiment_word(data$cleaned_text[1])\n```\n\n# Using these functions in loop\n\nYou can use these function with `for` loop or just use `map`to apply a them to each element of a vector or list in tibble.\n\n```{r message=FALSE, eval=FALSE}\ndata <- data %>%\n    mutate(sentiment_asent = map(cleaned_text, get_sentiment_asent, .progress = TRUE))\n```\n","srcMarkdownNoYaml":"\n\n```{=html}\n<style>\nbody {text-align: justify}\n</style>\n```\n![](images/sentiment.png){fig-align=\"center\" width=\"500\"}\n\nText analysis enables the identification and extraction of sentiment information from text. By leveraging tools such as `asent`, `sentimentr`, and basic sentiment lexicons, it is possible to construct a sentiment classifier that can estimate whether the underlying sentiment of a given text is positive, negative, or neutral.\n\n# Pacakage Management\n\nUsing `pacman` to manage package dependencies.\n\n```{r message=FALSE, warning=FALSE}\nrequire(pacman)\np_load(dplyr, magrittr, furrr, purrr, DT, readr, stringr, furrr, purrr, sentimentr, tidyfst, tidyr, textclean, tidytext, tibble, kableExtra)\n```\n\n# Load Data\n\nOur demonstration data are sourced from a news dataset collected from Factiva, consisting of 500 observations. The \"link\" refers to the links of these news articles. These news articles have been translated into English and undergone thorough text cleaning. Please find the data [here.](https://drive.google.com/file/d/1JKj8rDatjionAYN1EhzFnSNBRNQkay0C/view){.external target=\"_blank\"}\n\n```{r}\ndata <- read_rds(\"E:/OneDrive - HKUST Connect/SOSC/paper_with_jean/group_meeting/fifth/data_for_analysis_share.Rds\")\nglimpse(data)\n```\n\n# Using asent\n\nTo use `asent`, a Python package in R, you need `reticulate` package to integrate Python code in your R script. You can change your python interpreter here:\n\n![](images/python_in_R.png){width=\"550\"}\n\n## install python packages:\n\nCall python in R.\n\n```{r message=FALSE}\nreticulate::use_python(\"C:\\\\Users\\\\xhuangcb\\\\anaconda3\\\\envs\\\\pytorch_gpu\\\\python.exe\") # call python in R\n```\n\nThen:\n\n```{r}\n#| echo: false\ntribble(\n    ~\"Tpying\", ~\"To install\",\n    \"!pip install spacy\", \"spacy\",\n    \"!pip install asent\", \"asent\",\n    \"!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl\", \"pre-trained model\"\n) %>% \n   kbl() %>%\n   kable_styling()\n```\n\n![](images/callpythoninr.png){width=\"550\"}\n\n## from OOP to FP\n\nPython is an object-oriented programming (OOP) language, and it is possible to convert Python classes into functions in R, which mainly support functional programming (FP).\n\n```{r message=FALSE}\nspacy <- reticulate::import(\"spacy\") # load spacy\n\nasent <- reticulate::import(\"asent\") # load asent\n\nnlp <- spacy$load(\"en_core_web_lg\") # load pre-trained model\n\nnlp$add_pipe(\"asent_en_v1\") # add asent pipe\n\nnlp_safe <- possibly(.f = nlp, otherwise = \"error!\") # error handling\n\nget_polarity <- nlp_safe(\"sentiment\")$get_extension(\"polarity\")[[3]] # load python function\n\nget_sentiment_asent <- \\(x) {\n    result <- nlp_safe(x) %>%\n        get_polarity() %>%\n        print() %>%\n        capture.output() %>%\n        str_extract_all(\"-?0\\\\.\\\\d+\") %>%\n        unlist() %>%\n        as.numeric()\n\n    names(result) <- c(\"neg\", \"neu\", \"pos\", \"compound\")\n\n    return(result)\n}\n```\n\nTry our function:\n\n```{r}\nget_sentiment_asent(data$cleaned_text[1])\n```\n\nIt is an analytical process of asent:\n\n![](images/result-01.png){width=\"680\"}\n\n# Using sentimentr\n\nOur function using `sentimentr`.\n\n```{r}\nget_sentences_safe <- possibly(.f = get_sentences, otherwise = \"error!\") # sentences cutter\n\nsentiment_by_safe <- possibly(.f = sentiment_by, otherwise = \"error!\") # sentiment classifier\n\nget_sentiemnt_sentimentr <- \\(x) {\n    x %>%\n        get_sentences_safe() %>%\n        sentiment_by_safe() %>%\n        unlist()\n}\n```\n\nTry it:\n\n```{r}\nget_sentiemnt_sentimentr(data$cleaned_text[1])\n```\n\n# Word-level\n\n```{r}\ncal_sentiment <- \\(x) {\n    x %>%\n        filter(value == 0) %>%\n        pull(value) %>%\n        length() -> neu\n\n    x %>%\n        filter(value > 0) %>%\n        pull(value) %>%\n        sum() -> pos\n\n    x %>%\n        filter(value < 0) %>%\n        pull(value) %>%\n        sum() -> neg\n    result <- c(neu, pos, neg)\n\n    names(result) <- c(\"neu\", \"pos\", \"neg\")\n\n    return(result)\n}\n\nget_sentiment_word <- \\(x) {\n    result <- x %>%\n        tibble(text = ., id = 1) %>%\n        unnest_tokens(word, text) %>%\n        filter(!word %in% stopwords::stopwords(source = \"stopwords-iso\")) %>%\n        left_join(get_sentiments(\"afinn\")) %>% # you can try different dict\n        replace_na(list(value = 0)) %>%\n        nest(data = !id) %>%\n        mutate(sentiment = map(data, cal_sentiment)) %>%\n        pull(sentiment) %>%\n        unlist()\n\n    return(result)\n}\n```\n\nTry it:\n\n```{r message=FALSE}\nget_sentiment_word(data$cleaned_text[1])\n```\n\n# Using these functions in loop\n\nYou can use these function with `for` loop or just use `map`to apply a them to each element of a vector or list in tibble.\n\n```{r message=FALSE, eval=FALSE}\ndata <- data %>%\n    mutate(sentiment_asent = map(cleaned_text, get_sentiment_asent, .progress = TRUE))\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"kable","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"show","code-overflow":"scroll","code-link":true,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../scss/styles.css"],"highlight-style":"gruvbox","toc":true,"toc-depth":3,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","preview":{"port":5555,"browser":true,"watch-inputs":true,"navigate":true},"bibliography":["../../bib/references.bib"],"csl":"../../bib/chicago-author-date.csl","knitr":{"opts_chunk":{"warning":false,"message":false,"error":false}},"code-annotations":"hover","editor":"visual","theme":{"light":["flatly","../../scss/light.scss"],"dark":["darkly","../../scss/dark.scss"]},"author":[{"name":"Xinzhuo Huang","orcid":"0009-0007-6448-5114","email":"xhuangcb@connect.ust.hk","affiliations":[{"name":"HKUST SOSC"}]}],"smooth-scroll":true,"code-block-bg":"#f5f5f5","code-block-border-left":"#E0E0E0","date-modified":"last-modified","toc-location":"right","link-citations":"yes","comments":{"giscus":{"repo":"xinzhuohkust/comments","theme":"light"},"hypothesis":{"theme":"clean"}},"title":"Sentence Level Sentiment Analysis","date":"Feb 20 2023","categories":["R","Python","Sentiment Analysis","Reticulate"],"description":"by calling Python in R","feed":true},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}